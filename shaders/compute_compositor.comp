#version 450
//#extension GL_EXT_debug_printf : require
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_shuffle : require
#extension GL_KHR_shader_subgroup_ballot : require

#include "global_binding.glsl"
#include "node_binding.glsl"

#include "common_util.glsl"
#include "math.glsl"
#include "subgroup_grid.glsl"
#include "depth_reproject.glsl"

layout (local_size_x = SUBGROUP_CAPACITY, local_size_y = WORKGROUP_SUBGROUP_COUNT, local_size_z = 1) in;

layout (set = 2, binding = 0, r32ui) uniform uimage2D outputAtomic;
layout (set = 2, binding = 1, rgba8) uniform image2D outputColor;

// probably want to do this where I find initial  nodeOriginWorldPos and nodeOriginWorldDirection with project higher level depth mip
//void mainAveragedExtrude()
//{
//    const ivec2 iScreenSize = globalUBO.screenSize;
//    const vec2 screenSize = vec2(iScreenSize);
//    const ivec2 iScreenCoord = ivec2(gl_GlobalInvocationID.xy);
//    const vec2 screenCoord = vec2(iScreenCoord);
//    const vec2 screenUV = UVFromCoord(screenCoord, screenSize);
//    const bool topTriangle =  gl_LocalInvocationID.y < gl_LocalInvocationID.x;
//
//    if (gl_LocalInvocationIndex == 0) {
//        const ivec2 iAveragedScreenSize = iScreenSize / LOCAL_SIZE;
//        const vec2 averagedScreenSize = vec2(iAveragedScreenSize);
//
//        const int averagedOffsetCount = 4;
//        const ivec2 averagedOffsets[averagedOffsetCount] = { { 0, 0 }, { 1, 1 }, { 1, 0 }, { 0, 1 } };
//        vec3 averagedWorldPos[averagedOffsetCount];
//        int validCount = 0;
//        for (int i = 0; i < averagedOffsetCount; ++i) {
//            const ivec2 averagedScreenCoord = ivec2(gl_WorkGroupID.xy) + averagedOffsets[i];
//            const uint averagedAtomicData = imageLoad(outputAveragedAtomic, averagedScreenCoord).r;
//            const float averagedGlobalNDCZ = UnpackFloat32FromUint32(averagedAtomicData);
//            const vec2 averagedScreenUV = UVFromCoord(averagedScreenCoord, averagedScreenSize);
//            const vec2 averagedScreenNDC = NDCFromUV(averagedScreenUV);
//            const vec4 averagedGlobalClipPos = ClipPosFromNDC(averagedScreenNDC, averagedGlobalNDCZ);
//            averagedWorldPos[i] = WorldPosFromGlobalClipPos(averagedGlobalClipPos);
//            validCount += int(averagedGlobalNDCZ > 0);
//        }
//
//        const vec3 xDiff = averagedWorldPos[1] - averagedWorldPos[0];
//        const vec3 yDiffTopTri = averagedWorldPos[0] - averagedWorldPos[2];
//        const vec3 yDiffBottomTri = averagedWorldPos[3] - averagedWorldPos[0];
//
//        sharedNodeOrigin.inValid = validCount != averagedOffsetCount;
//        sharedNodeOrigin.worldPos = averagedWorldPos[0];
//        sharedNodeOrigin.topTriWorldDir = normalize(cross(xDiff, yDiffTopTri));
//        sharedNodeOrigin.bottomTriWorldDir = normalize(cross(xDiff, yDiffBottomTri));
//    }
//
//    barrier();
//
//    // can't discern if this subgroupBroadcastFirst actually speeds things up vs reading shared mem directly
//    const bool inValid = subgroupBroadcastFirst(sharedNodeOrigin.inValid);
//    if (inValid) {
//        return;
//    }
//    nodeOrigin.worldPos = subgroupBroadcastFirst(sharedNodeOrigin.worldPos);
//    const vec3 topWorldDir = subgroupBroadcastFirst(sharedNodeOrigin.topTriWorldDir);
//    const vec3 bottomWorldDir = subgroupBroadcastFirst(sharedNodeOrigin.bottomTriWorldDir);
//    nodeOrigin.worldDir = topTriangle ? topWorldDir : bottomWorldDir;
//
//    //    nodeOrigin.worldPos = vec3(0, 0, 0);
//    //    nodeOrigin.worldDir = vec3(0, 0, -1);
//
//    // source pixel
//    vec3 intersectNodeNDC;
//    vec3 depthProjectedGlobalNDC;
//    if (!NodeIntersect(screenUV, intersectNodeNDC, depthProjectedGlobalNDC)) {
//        return;
//    }
//    const vec2 intersectNodeUV = UVFromNDC(intersectNodeNDC);
//
//    const vec2 depthProjectedGlobalUV = UVFromNDC(depthProjectedGlobalNDC);
//    const vec3 color = texture(nodeColor, intersectNodeUV).xyz;
//    const uint packedData = packFloatAnd565Color(depthProjectedGlobalNDC.z, color);
////    const vec2 depthProjectedGlobalCoord = round(depthProjectedGlobalUV * screenSize);
//    const vec2 depthProjectGlobalCoord = depthProjectedGlobalUV * screenSize;
//    const ivec2 depthProjectGlobalCoordCeil = ivec2(ceil(depthProjectGlobalCoord));
//    const ivec2 depthProjectGlobalCoordFloor = ivec2(floor(depthProjectGlobalCoord));
//
//    imageAtomicMax(outputAtomic, ivec2(depthProjectGlobalCoordCeil), packedData);
//    imageAtomicMax(outputAtomic, ivec2(depthProjectGlobalCoordCeil.x, depthProjectGlobalCoordFloor.y), packedData);
//    imageAtomicMax(outputAtomic, ivec2(depthProjectGlobalCoordFloor.x, depthProjectGlobalCoordCeil.y), packedData);
//    imageAtomicMax(outputAtomic, ivec2(depthProjectGlobalCoordFloor), packedData);
//
//    // Stepback -- TODO may be better to just double sample, no you can write two pixels faster in one thread than two threads
//    //    const vec3 intersectGlobalNDC = GlobalNDCFromNodeNDC(intersectNodeNDC);
//    //    const vec2 intersectGlobalUV = UVFromNDC(intersectGlobalNDC);
//    //    // do the stepback in NDC to get a new Z value too
//    //    const vec2 stepBackDir = depthProjectedGlobalUV - intersectGlobalUV;
//    //    const vec2 normalizedStepBackDir = XYCoordNormalizedDir(stepBackDir);
//    //    const ivec2 stepBackCoord = ivec2(round(depthProjectedGlobalCoord + normalizedStepBackDir));
//    //    // need to figure how much z to subtract on this
//    //    imageAtomicMax(outputAtomic, ivec2(depthProjectedGlobalCoord), packedData);
//}

void main()
{
    ivec2 outputSize = imageSize(outputColor);
    InitializeSubgroupGridInfo(outputSize);

    {
        vec2 globalUV = grid_GlobalCoord / vec2(outputSize);

        vec3 nodeOriginWorldPos = vec3(0, 0, 0);
        vec3 nodeOriginWorldDirection = vec3(0, 0, -1);

        vec3 intersectNodeNDC = IntersectNodeNDC(nodeOriginWorldPos, nodeOriginWorldDirection, globalUV);
        vec2 intersectNodeUV = UVFromNDC(intersectNodeNDC);

        //this should be constrained the rect where it is in the framebuffer
    //    if (intersectNodeUVs[i].x < 0 || intersectNodeUVs[i].x > 1 || intersectNodeUVs[i].y < 0 || intersectNodeUVs[i].y > 1)
    //        return;

        ivec2 intersectNodeCoord = CoordFromUVRound(intersectNodeUV, outputSize);
        float nodeDepthSample = texelFetch(nodeGBuffer, intersectNodeCoord, 0).r;
        // use imageload I could also write dpeth into color?
        // it is also true that technically this would be more accurate linear sampled

//        float nodeDepthSample = texture(nodeGBuffer, intersectNodeUV).r;
        vec4 nodeProjClipPos = ClipPosFromNDC(intersectNodeNDC.xy, nodeDepthSample);
        vec3 projWorldPos = WorldPosFromNodeClipPos(nodeProjClipPos);
        vec4 globProjClipPos = GlobalClipPosFromWorldPos(projWorldPos);
        vec3 globProjNDC = NDCFromClipPos(globProjClipPos);
        float globProjDepth = globProjNDC.z;

        if (!(globProjDepth > 0))
            return;

        vec2 globProjUV = UVFromNDC(globProjNDC);
        ivec2 globProjCoord = CoordFromUVRound(globProjUV, outputSize);

        // I am going to want to pack depth with an ID of the node eventually then use that id to sample the color
        uint nodePackedDepth = PackDepth16(globProjDepth);
        uint prevNodePackedDepth = imageAtomicMax(outputAtomic, globProjCoord, nodePackedDepth);

        if (nodePackedDepth > prevNodePackedDepth){
            vec4 nodeColorSample = texture(nodeColor, intersectNodeUV);
            imageStore(outputColor, globProjCoord, nodeColorSample);
        }
    }
}
