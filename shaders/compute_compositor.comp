#version 450
//#extension GL_EXT_debug_printf : require
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_shuffle : require
#extension GL_KHR_shader_subgroup_ballot : require

#include "global_binding.glsl"
#include "node_binding.glsl"

#include "common_util.glsl"
#include "math.glsl"
#include "subgroup_grid.glsl"
#include "depth_reproject.glsl"

layout (local_size_x = SUBGROUP_CAPACITY, local_size_y = WORKGROUP_SUBGROUP_COUNT, local_size_z = 1) in;

layout (set = 2, binding = 0, r32ui) uniform uimage2D outputAtomic;
layout (set = 2, binding = 1, rgba8) uniform image2D outputColor;

// probably want to do this where I find initial  nodeOriginWorldPos and nodeOriginWorldDirection with project higher level depth mip
//void mainAveragedExtrude()
//{
//    const ivec2 iScreenSize = globalUBO.screenSize;
//    const vec2 screenSize = vec2(iScreenSize);
//    const ivec2 iScreenCoord = ivec2(gl_GlobalInvocationID.xy);
//    const vec2 screenCoord = vec2(iScreenCoord);
//    const vec2 screenUV = UVFromCoord(screenCoord, screenSize);
//    const bool topTriangle =  gl_LocalInvocationID.y < gl_LocalInvocationID.x;
//
//    if (gl_LocalInvocationIndex == 0) {
//        const ivec2 iAveragedScreenSize = iScreenSize / LOCAL_SIZE;
//        const vec2 averagedScreenSize = vec2(iAveragedScreenSize);
//
//        const int averagedOffsetCount = 4;
//        const ivec2 averagedOffsets[averagedOffsetCount] = { { 0, 0 }, { 1, 1 }, { 1, 0 }, { 0, 1 } };
//        vec3 averagedWorldPos[averagedOffsetCount];
//        int validCount = 0;
//        for (int i = 0; i < averagedOffsetCount; ++i) {
//            const ivec2 averagedScreenCoord = ivec2(gl_WorkGroupID.xy) + averagedOffsets[i];
//            const uint averagedAtomicData = imageLoad(outputAveragedAtomic, averagedScreenCoord).r;
//            const float averagedGlobalNDCZ = UnpackFloat32FromUint32(averagedAtomicData);
//            const vec2 averagedScreenUV = UVFromCoord(averagedScreenCoord, averagedScreenSize);
//            const vec2 averagedScreenNDC = NDCFromUV(averagedScreenUV);
//            const vec4 averagedGlobalClipPos = ClipPosFromNDC(averagedScreenNDC, averagedGlobalNDCZ);
//            averagedWorldPos[i] = WorldPosFromGlobalClipPos(averagedGlobalClipPos);
//            validCount += int(averagedGlobalNDCZ > 0);
//        }
//
//        const vec3 xDiff = averagedWorldPos[1] - averagedWorldPos[0];
//        const vec3 yDiffTopTri = averagedWorldPos[0] - averagedWorldPos[2];
//        const vec3 yDiffBottomTri = averagedWorldPos[3] - averagedWorldPos[0];
//
//        sharedNodeOrigin.inValid = validCount != averagedOffsetCount;
//        sharedNodeOrigin.worldPos = averagedWorldPos[0];
//        sharedNodeOrigin.topTriWorldDir = normalize(cross(xDiff, yDiffTopTri));
//        sharedNodeOrigin.bottomTriWorldDir = normalize(cross(xDiff, yDiffBottomTri));
//    }
//
//    barrier();
//
//    // can't discern if this subgroupBroadcastFirst actually speeds things up vs reading shared mem directly
//    const bool inValid = subgroupBroadcastFirst(sharedNodeOrigin.inValid);
//    if (inValid) {
//        return;
//    }
//    nodeOrigin.worldPos = subgroupBroadcastFirst(sharedNodeOrigin.worldPos);
//    const vec3 topWorldDir = subgroupBroadcastFirst(sharedNodeOrigin.topTriWorldDir);
//    const vec3 bottomWorldDir = subgroupBroadcastFirst(sharedNodeOrigin.bottomTriWorldDir);
//    nodeOrigin.worldDir = topTriangle ? topWorldDir : bottomWorldDir;
//
//    //    nodeOrigin.worldPos = vec3(0, 0, 0);
//    //    nodeOrigin.worldDir = vec3(0, 0, -1);
//
//    // source pixel
//    vec3 intersectNodeNDC;
//    vec3 depthProjectedGlobalNDC;
//    if (!NodeIntersect(screenUV, intersectNodeNDC, depthProjectedGlobalNDC)) {
//        return;
//    }
//    const vec2 intersectNodeUV = UVFromNDC(intersectNodeNDC);
//
//    const vec2 depthProjectedGlobalUV = UVFromNDC(depthProjectedGlobalNDC);
//    const vec3 color = texture(nodeColor, intersectNodeUV).xyz;
//    const uint packedData = packFloatAnd565Color(depthProjectedGlobalNDC.z, color);
////    const vec2 depthProjectedGlobalCoord = round(depthProjectedGlobalUV * screenSize);
//    const vec2 depthProjectGlobalCoord = depthProjectedGlobalUV * screenSize;
//    const ivec2 depthProjectGlobalCoordCeil = ivec2(ceil(depthProjectGlobalCoord));
//    const ivec2 depthProjectGlobalCoordFloor = ivec2(floor(depthProjectGlobalCoord));
//
//    imageAtomicMax(outputAtomic, ivec2(depthProjectGlobalCoordCeil), packedData);
//    imageAtomicMax(outputAtomic, ivec2(depthProjectGlobalCoordCeil.x, depthProjectGlobalCoordFloor.y), packedData);
//    imageAtomicMax(outputAtomic, ivec2(depthProjectGlobalCoordFloor.x, depthProjectGlobalCoordCeil.y), packedData);
//    imageAtomicMax(outputAtomic, ivec2(depthProjectGlobalCoordFloor), packedData);
//
//    // Stepback -- TODO may be better to just double sample, no you can write two pixels faster in one thread than two threads
//    //    const vec3 intersectGlobalNDC = GlobalNDCFromNodeNDC(intersectNodeNDC);
//    //    const vec2 intersectGlobalUV = UVFromNDC(intersectGlobalNDC);
//    //    // do the stepback in NDC to get a new Z value too
//    //    const vec2 stepBackDir = depthProjectedGlobalUV - intersectGlobalUV;
//    //    const vec2 normalizedStepBackDir = XYCoordNormalizedDir(stepBackDir);
//    //    const ivec2 stepBackCoord = ivec2(round(depthProjectedGlobalCoord + normalizedStepBackDir));
//    //    // need to figure how much z to subtract on this
//    //    imageAtomicMax(outputAtomic, ivec2(depthProjectedGlobalCoord), packedData);
//}

void StoreDebug(){
    imageAtomicMax(outputAtomic, grid_GlobalCoord, 1);
    imageStore(outputColor, grid_GlobalCoord, vec4(0,1,0,1));
}

void main()
{
    ivec2 outputSize = imageSize(outputColor);
    InitializeSubgroupGridInfo(outputSize);

    if (any(greaterThan(nodeUBO.ulUV, vec2(1.0))) || any(lessThan(nodeUBO.lrUV, vec2(0.0)))) {
        StoreDebug();
        return;
    }

    vec2 nodeOriginNDC = vec2(0,0);
    vec3 nodeOriginWorldPos = vec3(0,0,0);
    vec3 nodeOriginWorldDir = -WorldRayDirFromNodeNDC(nodeOriginNDC);

    vec2 globalUV = vec2(grid_GlobalCoord) / vec2(outputSize);
    vec2 globalNDC = NDCFromUV(globalUV);
    vec4 globalClipPos = ClipPosFromNDC(globalNDC, DEPTH_NEAR);
    vec3 globalWorldPos = WorldPosFromGlobalClipPos(globalClipPos);
    vec3 globalWorldDir = WorldRayDirFromGlobalNDC2(globalNDC);

//    vec4 testDepth = texture(nodeGBuffer, globalUV);
//    imageAtomicMax(outputAtomic, grid_GlobalCoord, 1);
//    imageStore(outputColor, grid_GlobalCoord, vec4(testDepth));
//    return;

    vec3 intersectWorldPos;
    if (!IntersectPlane(globalWorldPos, globalWorldDir, nodeOriginWorldPos, nodeOriginWorldDir, intersectWorldPos)) {
        StoreDebug();
        return;
    }

    vec4 intersectGlobalClipPos = GlobalClipPosFromWorldPos(intersectWorldPos);
    vec3 intersectGlobalNDC = NDCFromClipPos(intersectGlobalClipPos);
    vec4 intersectNodeClipPos = NodeClipPosFromWorldPos(intersectWorldPos);
    vec3 intersectNodeNDC = NDCFromClipPos(intersectNodeClipPos);
    vec2 intersectNodeUV = UVFromNDC(intersectNodeNDC);

    //this should be constrained the rect where it is in the framebuffer
    if (any(lessThan(intersectNodeUV, nodeUBO.ulUV)) || any(greaterThan(intersectNodeUV, nodeUBO.lrUV))) {
        StoreDebug();
        return;
    }

    // Linear sample with gbuffer dilate on depth or texelFetch/ImageLoad ?!?!
    // I honestly do not know which is better.
    // One reason to not linearly sample depth is that the transition between actual objects of different depths
    // will not have interpolated pixel spread between them
    ivec2 intersectNodeCoord = CoordFromUVRound(intersectNodeUV, outputSize);
    float nodeDepthSample = texelFetch(nodeGBuffer, intersectNodeCoord, 0).r;

//        float nodeDepthSample = texture(nodeGBuffer, intersectNodeUV).r;
    vec4 nodeProjClipPos = ClipPosFromNDC(intersectNodeNDC.xy, nodeDepthSample);
    vec3 projWorldPos = WorldPosFromNodeClipPos(nodeProjClipPos);
    vec4 globProjClipPos = GlobalClipPosFromWorldPos(projWorldPos);
    vec3 globProjNDC = NDCFromClipPos(globProjClipPos);
    float globProjDepth = globProjNDC.z;
    vec2 globProjUV = UVFromNDC(globProjNDC);
    ivec2 globProjCoord = CoordFromUVRound(globProjUV, outputSize);

//    imageAtomicMax(outputAtomic, grid_GlobalCoord, 1);
////    vec4 testColor = texture(nodeColor, intersectNodeUV);
////    vec4 testColor = texture(nodeColor, globalUV);
//    vec4 testColor = texelFetch(nodeColor, grid_GlobalCoord, 0);
//    imageStore(outputColor, globProjCoord, testColor);
//    return;

    if (!(globProjDepth > DEPTH_FAR))
        return;

    // I am going to want to pack depth with an ID of the node eventually then use that id to sample the color
    uint nodePackedDepth = PackDepth16(globProjDepth);
    uint prevNodePackedDepth = imageAtomicMax(outputAtomic, globProjCoord, nodePackedDepth);

    if (nodePackedDepth > prevNodePackedDepth){
        vec4 nodeColorSample = texelFetch(nodeColor, intersectNodeCoord, 0);
//        vec4 nodeColorSample = texture(nodeColor, intersectNodeUV);
        imageStore(outputColor, globProjCoord, nodeColorSample);
    }
}
